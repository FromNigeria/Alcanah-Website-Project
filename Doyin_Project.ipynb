{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EERSlBpWymRwk4ojOIR8VT9Xpfgoj4-H",
      "authorship_tag": "ABX9TyMQ8cVTHIjBaJBFx77XeX/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FromNigeria/Alcanah-Website-Project/blob/master/Doyin_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFHssw0SyoV6"
      },
      "outputs": [],
      "source": [
        "#pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution\n",
        "# import our modules in order to extract product details for a clientâ€™s pre-defined list of ASINs\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import string\n",
        "import numpy as np \n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from wordcloud import WordCloud\n",
        "from textblob import TextBlob\n",
        "pd.set_option('display.max_colwidth', None)#None\n",
        "import unicodedata\n",
        "import warnings\n",
        "from tkinter import X\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as sid\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n"
      ],
      "metadata": {
        "id": "5VKNSlzxzJ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "Wx-npIjyzJ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking column datatype using lambda\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/subset_tweets.csv\",parse_dates=['Date'], dayfirst=True,usecols=['Date','text'])\n",
        "print(\"No of Rows and Columns\",df.shape)\n",
        "raw_data = df.copy()\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HB32D2Qw51e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "naKsJKJZ51ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']= df['text'].str.lower()#lowercase the text\n",
        "\n",
        "def strip_links(text):##remove hyperlinks url\n",
        "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
        "    links         = re.findall(link_regex, text)\n",
        "    for link in links:\n",
        "        text = text.replace(link[0], ', ')    \n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: strip_links(x))  \n",
        "\n",
        "#2ndly strip_all_entities like tweeter mentions, hashtags and stuff\n",
        "\n",
        "def strip_all_entities(text):\n",
        "    entity_prefixes = ['@','#']\n",
        "    for separator in  string.punctuation:\n",
        "        if separator not in entity_prefixes :\n",
        "            text = text.replace(separator,' ')\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: strip_all_entities(x))\n",
        "\n",
        "df['text'] = df['text'].str.findall('\\w{4,}').str.join(' ')\n",
        "\n",
        "\n",
        "#3 get rid of special_characters\n",
        "def special_characters(text):\n",
        "    return re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", text)\n",
        "df['text'] = df['text'].apply(lambda x: special_characters(x))\n",
        "\n",
        "\n",
        "#remove some special nos too\n",
        "def special_nos(text):\n",
        "    return re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", text)\n",
        "df['text'] = df['text'].apply(lambda x: special_nos(x))\n",
        "\n",
        "#remove duplicates words\n",
        "df['text'] = df['text'].str.replace(r'\\b(\\w+)(\\s+\\1)+\\b', r'\\1')\n",
        "\n",
        "\n",
        "#Removing '\\n' in text\n",
        "df['text'] = df['text'].replace(r'\\s+|\\\\n', ' ', regex=True) \n",
        "\n",
        "# we can still try remove numbers from string like e.g donald65 -->  donald\n",
        "df['text'] = df['text'].str.replace('\\d+', '')\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iKqFNk4751kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "UPzkLS2AQnu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#stop_words = 'twitter','cryptosoul', 'retweets', 'bicoin','coinmarketcap','bdt','ref', 'doge','idap','ppbb','kyc', 'cryptocurrency','binance','ethereum', 'tweets', 'tweet', 'fscebook', 'btc', 'crypto', 'utc','xrp', 'like', 'currencies', 'coin','litecoin', 'altcoin','btcusd','altcoin','airdrop'\n",
        "#df_clean['text'] = df_clean['text'].replace(stop_words,'', inplace = True)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('bitcoin', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('airdrop', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('cryptosoul', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('satoshi', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('utc', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('btc', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('bitsler', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('mgkdve', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('cryptosoul', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('trading', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('bitsler', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('coin', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('bdt', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('kyc', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('amp', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('bitdepositary', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('blockchain', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('p2pb2b', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('idap', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('ref', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('crypto', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('trading', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('cryptocurrencies', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('lablxvx', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('lxvx', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('tweet', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('twitter', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('binance', '')\n",
        "                              if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('coinmarket', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('ethereum', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('ada', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('follow', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('retweet', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('just', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('xrp', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('eth', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('utc', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('$', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('usd', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('exmo', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('think', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('good', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('ppbb', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('litecoin', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('altcoin', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('rt', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('btcusd', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('facebook', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('kyc', '')\n",
        "                                if isinstance(x, str) else x).astype(str)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('doge', '')\n",
        "                                if isinstance(x, str) else x).astype(str) \n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('woh', '')\n",
        "                                if isinstance(x, str) else x).astype(str)  \n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('erral', '')\n",
        "                                if isinstance(x, str) else x).astype(str) \n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('com', '')\n",
        "                                if isinstance(x, str) else x).astype(str)                                \n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('erral', '')\n",
        "                                if isinstance(x, str) else x).astype(str) \n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('like', '')\n",
        "                                if isinstance(x, str) else x).astype(str) \n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('link', '')\n",
        "                                if isinstance(x, str) else x).astype(str)                              \n",
        "\n",
        "df_clean = df.copy()                             \n",
        "df_clean.tail()"
      ],
      "metadata": {
        "id": "eDIUC3kxF3zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.head()"
      ],
      "metadata": {
        "id": "CtZtMXpNF9hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean['text'] = df_clean['text'].str.replace(r'\\b(\\w{1,3})\\b', '')#remove words less than 3 for me\n",
        "cv = CountVectorizer(stop_words = 'english')\n",
        "words = cv.fit_transform(df_clean.text)\n",
        "\n",
        "sum_words = words.sum(axis=0)\n",
        "\n",
        "words_freq = [(word, sum_words[0, i]) for word, i in cv.vocabulary_.items()]\n",
        "words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
        "words_freq"
      ],
      "metadata": {
        "id": "aRo0SruC8iib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
        "\n",
        "frequency.head(30).plot(x='word', y='freq', kind='bar', figsize=(15, 7), color = 'blue')\n",
        "plt.title(\"Most Frequently Occuring Words - Top 30\")"
      ],
      "metadata": {
        "id": "OHjo0Jg151mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from wordcloud import WordCloud\n",
        "tweets = df_clean['text'].tolist()#df_clean['text']\n",
        "\n",
        "tweets_as_one_string =\" \".join(tweets)\n",
        "tweets_as_one_string\n",
        "\n",
        "plt.figure(figsize=(7,5))#setting figure size\n",
        "plt.imshow(WordCloud().generate(tweets_as_one_string))\n",
        "\n",
        "df.tail() "
      ],
      "metadata": {
        "id": "5rI_CQGA51o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_vader = df_clean.copy()\n",
        "df_vader.head()"
      ],
      "metadata": {
        "id": "BuVMWhVQd6s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VARder Model\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "cs = []\n",
        "for row in range(len(df_vader)):\n",
        "    cs.append(analyzer.polarity_scores(df_vader['text'].iloc[row])['compound'])\n",
        "\n",
        "df_vader['compound_vader_score'] = cs\n",
        "df_vader = df_vader[(df_vader[['compound_vader_score']] != 0).all(axis=1)].reset_index(drop=True)\n",
        "\n",
        "df_vader.head()"
      ],
      "metadata": {
        "id": "aeizxgq-51q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retaining extreme maximum and minimum compound scores for same day in sub_tweets comments\n",
        "\n",
        "unique_dates = df_vader['Date'].unique()#group by unique dates\n",
        "grouped_dates = df_vader.groupby(['Date'])\n",
        "keys_dates = list(grouped_dates.groups.keys())#get the key dates\n",
        "\n",
        "max_cs = []#cretae empty max\n",
        "min_cs = [] #min \n",
        "\n",
        "for key in grouped_dates.groups.keys():#using for loop\n",
        "    data = grouped_dates.get_group(key)\n",
        "    if data[\"compound_vader_score\"].max() > 0:\n",
        "        max_cs.append(data[\"compound_vader_score\"].max())\n",
        "    elif data[\"compound_vader_score\"].max() < 0:\n",
        "        max_cs.append(0)\n",
        "    \n",
        "    if data[\"compound_vader_score\"].min() < 0:\n",
        "        min_cs.append(data[\"compound_vader_score\"].min())\n",
        "    elif data[\"compound_vader_score\"].min() > 0:\n",
        "        min_cs.append(0)\n",
        "    \n",
        "extreme_scores_dict = {'Date':keys_dates,'max_scores':max_cs,'min_scores':min_cs}\n",
        "extreme_scores_df = pd.DataFrame(extreme_scores_dict)\n",
        "extreme_scores_df"
      ],
      "metadata": {
        "id": "I6II6ldH51uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summing and calculating the final VADER scores\n",
        "final_scores = []\n",
        "for i in range(len(extreme_scores_df)):\n",
        "    final_scores.append(extreme_scores_df['max_scores'].values[i] + extreme_scores_df['min_scores'].values[i])\n",
        "\n",
        "extreme_scores_df['final_scores'] = final_scores\n",
        "\n",
        "extreme_scores_df.head()"
      ],
      "metadata": {
        "id": "P4PTsSU2lC2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using final our compound VADER scores with threshold to generate trade calls\n",
        "#knowing how volatile behavior of bitcoin market eh these days, we can try use 0.20 as maybe threshold value for making bitcoin calls in our model based on\n",
        "#kind of tweet commments for a given day\n",
        "# VADER trade calls - with threshold\n",
        "#you can check their documentation sha here, https://github.com/cjhutto/vaderSentiment\n",
        "vader_Buy=[]\n",
        "vader_Sell=[]\n",
        "for i in range(len(extreme_scores_df)):\n",
        "    if extreme_scores_df['final_scores'].values[i] > 0.20:\n",
        "        print(\"Bitcoin prediction Call for {row} is Buy.\".format(row=extreme_scores_df['Date'].iloc[i].date()))\n",
        "        vader_Buy.append(extreme_scores_df['Date'].iloc[i].date())\n",
        "    elif extreme_scores_df['final_scores'].values[i] < 0.20:\n",
        "        print(\"Bitcoin prediction Call for {row} is Sell.\".format(row=extreme_scores_df['Date'].iloc[i].date()))\n",
        "        vader_Sell.append(extreme_scores_df['Date'].iloc[i].date())"
      ],
      "metadata": {
        "id": "6iHUw89-lC4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCsBbqO8lC7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ue0iUE-LlC-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}