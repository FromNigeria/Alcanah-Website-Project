{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1EERSlBpWymRwk4ojOIR8VT9Xpfgoj4-H",
      "authorship_tag": "ABX9TyO5JmeIudFUjgh7zbi9xp8K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FromNigeria/Alcanah-Website-Project/blob/master/Doyin_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFHssw0SyoV6"
      },
      "outputs": [],
      "source": [
        "#pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution\n",
        "# import our modules in order to extract product details for a clientâ€™s pre-defined list of ASINs\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import string\n",
        "import numpy as np \n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from wordcloud import WordCloud\n",
        "from textblob import TextBlob\n",
        "pd.set_option('display.max_colwidth', None)#None\n",
        "import unicodedata\n",
        "import warnings\n",
        "from tkinter import X\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as sid\n"
      ],
      "metadata": {
        "id": "5VKNSlzxzJ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "Wx-npIjyzJ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking column datatype using lambda\n",
        "df = pd.read_csv(\"sample_data/subset_tweets.csv\",parse_dates=['Date'], dayfirst=True,usecols=['Date','text'])\n",
        "print(\"No of Rows and Columns\",df.shape)\n",
        "\n",
        "raw_data = df.copy()\n",
        "df.head()\n",
        "df['data_type'] = df['text'].apply(lambda x: type(x).__name__)#We can also check the dtypes\n",
        "print(df['data_type'].unique())#seems like the column text are all pandas object type\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HB32D2Qw51e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "naKsJKJZ51ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKqFNk4751kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHjo0Jg151mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rI_CQGA51o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aeizxgq-51q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6II6ldH51uQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}